{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e737ae3b-1855-40c9-ad3e-acf835c64c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 16:35:16 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-02-14 16:35:16 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2022-02-14 16:35:16 INFO: Use device: cpu\n",
      "2022-02-14 16:35:16 INFO: Loading: tokenize\n",
      "2022-02-14 16:35:16 INFO: Loading: pos\n",
      "2022-02-14 16:35:17 INFO: Loading: lemma\n",
      "2022-02-14 16:35:17 INFO: Loading: depparse\n",
      "2022-02-14 16:35:18 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk import tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import stanza\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp_stanford = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "94073f02-701b-4074-a163-541a32901dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A language is a structured system of communication used by humans. Languages can be based on speech and gesture (spoken language), sign, or writing. The structure of language is its grammar and the free components are its vocabulary. Many languages, including the most widely spoken ones, have writing systems that enable sounds or signs to be recorded for later reactivation. Human language is unique among the known systems of animal communication in that it is not dependent on a single mode of transmission, is highly variable between cultures and across time, and affords a much wider range of expression than other systems.\n",
      "         Tokens relation_to_head_spacy      Parent               Children\n",
      "0             A                    det    language                     []\n",
      "1      language                  nsubj          is                    [A]\n",
      "2            is                   ROOT          is  [language, system, .]\n",
      "3             a                    det      system                     []\n",
      "4    structured                   amod      system                     []\n",
      "..          ...                    ...         ...                    ...\n",
      "110  expression                   pobj          of                 [than]\n",
      "111        than                   prep  expression              [systems]\n",
      "112       other                   amod     systems                     []\n",
      "113     systems                   pobj        than                [other]\n",
      "114           .                  punct          is                     []\n",
      "\n",
      "[115 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('test.txt') as test:\n",
    "    sentences = test.readlines()\n",
    "\n",
    "for content in sentences:\n",
    "    print(content)\n",
    "\n",
    "split_content = tokenize.sent_tokenize(content)\n",
    "tokenized_content = word_tokenize(content)\n",
    "\n",
    "## preprocessing some small things, such as punctuation inbetween a word. Widely-spoken causes the problem that spacy wants to split this, which results in problems when adding it to the dataframe.\n",
    "\n",
    "new_df = pd.DataFrame(data=tokenized_content, columns=['Tokens'])\n",
    "\n",
    "tokenlist = new_df['Tokens'].tolist()\n",
    "\n",
    "d = []\n",
    "for word in split_content:\n",
    "    doc = nlp(word)\n",
    "    dependency_list = []\n",
    "    for item in doc:\n",
    "        dependency_list.append(item.dep_)\n",
    "    d.append(dependency_list)\n",
    "\n",
    "list_dep = []\n",
    "for item in d:\n",
    "    #print(item)\n",
    "    for dep in item:\n",
    "        list_dep.append(dep)\n",
    "new_df['relation_to_head_spacy'] = list_dep\n",
    "\n",
    "d = []\n",
    "for word in split_content:\n",
    "    doc = nlp(word)\n",
    "    dependency_list = []\n",
    "    for item in doc:\n",
    "        dependency_list.append(item.head)\n",
    "    d.append(dependency_list)\n",
    "\n",
    "list_parent = []\n",
    "for item in d:\n",
    "    #print(item)\n",
    "    for parent in item:\n",
    "        list_parent.append(parent)\n",
    "new_df['Parent'] = list_parent\n",
    "\n",
    "#print(new_df)\n",
    "\n",
    "d = []\n",
    "for word in split_content:\n",
    "    doc = nlp(word)\n",
    "    children_list = [list(t.children) for t in doc]\n",
    "    #print(children_list)\n",
    "    d.append(children_list)\n",
    "    \n",
    "list_children = []\n",
    "for item in d:\n",
    "    #print(item)\n",
    "    for child in item:        \n",
    "        list_children.append(child)\n",
    "new_df['Children'] = list_children\n",
    "\n",
    "print(new_df)\n",
    "\n",
    "# convert pandas df to .conll file (uncomment when ready to use)\n",
    "# outputfile = \"test_dependency.conll\"\n",
    "# new_df.to_csv(f'c:/Users/desir/Desktop/text_mining/applied TM/{outputfile}', sep='\\t', header=True, quotechar='|', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b2d04147-e082-4db0-bb4e-ac387db0a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_d = []\n",
    "for sentences in split_content:\n",
    "    #print(sentences)\n",
    "    doc_stanford= nlp_stanford(sentences)\n",
    "    #print(doc_stanford)\n",
    "    new_d.append(doc_stanford)\n",
    "#print(new_d)\n",
    "\n",
    "\n",
    "\n",
    "#for word in new_d:\n",
    "   # print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757e193-d56d-4c6d-b753-1c8735aeeef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
